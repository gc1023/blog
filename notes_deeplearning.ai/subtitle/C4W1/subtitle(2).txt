You've seen how the convolution
operation allows you to implement a vertical edge detector. In this video, you learn the difference
between positive and negative edges. That is, the difference between
light to dark, versus dark to light, edge transitions. And you also see other
types of edge detectors, as well as how to have an algorithm learn. Rather than having us hand coding an edge
detector, as we've been doing so far, so let's get started, Here's the example
you saw from the previous video, where you have this image, 6 by 6, that's
light on the left and dark on the right. And convolving it with
the vertical edge detection filter results in detecting the vertical
edge down the middle of the image. What happens in an image
where the colors are flipped, where it is darker on the left,
and brighter on the right? So the 10s are now on the right half
of the image, and the 0s on the left. If you convolve it with
the same edge detection filter, you end up with -30 instead
of 30 down the middle. And you can plot that as a picture,
and it will look like that. Because the shade of
the transition is reversed, the 30s now get reversed as well. And -30s shows that this
is a dark to light, rather than a light to dark transition. And if you don't care which
of these two cases it is, you could take absolute
values of this output matrix. But this particular filter does make
a difference between the light to dark, versus the dark to light edges. Let's see some more
examples of edge detection. This 3 by 3 filter we've seen allows
you to detect vertical edges. Maybe it should not surprise you too much, that this 3 by 3 filter will allow
you to detect horizontal edges. As a reminder, a vertical edge,
according to this filter, is a 3 by 3 region where the pixels are
relatively bright on the left part, and relatively dark on the right part. Similarly, a horizontal edge would be
a [INAUDIBLE] division, where the pixels are relatively bright on top, and
relatively dark in the bottom row. Here's one example,
this is a more complex one, where you have here 10s in the upper
left and lower right hand corners. If you draw this as an image, this is an image which is going
to be darker where there's 0s. I'm going to shade in the darker regions,
and then lighter in the upper left, and lower right hand corners. And if you convolve this with a horizontal
edge detector, you end up with this. And so, just to take a couple examples, this 30 here corresponds
to this 3 by 3 region. Where indeed there are bright pixels on
top, and darker pixels on the bottom, over here, and so
it finds a strong positive edge there. And this -30 here
corresponds to this region, which is actually brighter
on the bottom and darker on top, so
that is a negative edge in this example. And again, this is kind of an artifact
of the fact that we're working with relatively small images,
that this is just a 6 by 6 image. But these intermediate values,
like this -10 for example, just reflects the fact that
that filter here, it captures part of the positive edge on the left, and
part of the negative edge on the right. And so blending those together
gives you some intermediate value. But if this was a very large,
say 1000 by 1000 image, with this type of checkerboard pattern, then you won't
see these transition regions of the 10s. The intermediate values would be quite
small relative to the size of the image. In summary, different filters allow you
to find vertical and horizontal edges. It turns out that the 3 by 3
vertical edge detection filter we've used is just one possible choice. And historically in
the computer vision literature, there was a fair amount of debate about
what is the best set of numbers to use. So here's something else you
could use which is maybe 1, 2, 1, 0, 0, 0 -1, -2, -1,
this is called a Sobel filter. And the advantage of this is, it puts a
little bit more weight to the central row, the central pixel, and this makes
it maybe a little bit more robust. But computer vision researchers will
use other sets of numbers as well. Like maybe, instead of a 1,
2, 1, it should be a 3, 10, 3, and then -3, -10, -3, and
this is called a Scharr filter, and this has yet
other slightly different properties. And this is just called vertical edge
detection, and if you flip it 90 degrees, you get horizontal edge detection. And with the rise of deep learning,
one of the things we learn is that, when you really want to detect
edges in some complicated image. Maybe you don't need to have computer
vision researchers hand pick these nine numbers,
maybe you can just learn them. And treat the nine numbers of this matrix
as parameters, which you can then learn using back propagation, and
the goal is to learn nine parameters. So that when you take the 6 by 6 image,
and convolve it with your 3 by 3 filter,
that this gives you a good edge detector. And what you see in later videos, is that by just treating these
nine numbers as parameters. The backprop can choose to learn 1,
1, 1, 0, 0, 0, -1, -1, -1, or learn the Sobel filter,
or the Scharr filter. Or more likely, learn something else, that
is even better at capturing the statistics of your data,
than any of this hand-coded filters. And rather than just vertical and horizontal edges, maybe it can learn to
detect edges that are at 45 degrees, or 70 degrees, or 73 degrees, or
whatever orientation it chooses. And so, by just letting all of
these numbers be parameters, and learning them automatically from data. We find that neural networks can
actually learn low level features, can learn features such as edges. Even more robustly than
computer vision researchers are generally able to code
out these things by hand. But underlying all these computations is still this convolution operation. Which allows back propagation to learn
whatever 3 by 3 filter it wants, and then to apply it throughout
the entire image. At this position, at this position,
at this position, in order to output whatever
feature it's trying to detect. Be it vertical edges, horizontal edges,
or edges at some odd angle. Or even some other filter that we might
not even have a name for in English. So the idea that you can treat these
nine numbers as parameters, we learn, has been one of the most powerful
ideas in computer vision. And later in this course, later this week,
we'll actually talk about the details of how you actually go about using back
propagation to learn these nine numbers. But first,
let's talk about some other details, some of the deviations of
the basic convolutional operation. In the next two videos, I want to
discuss with you how to use padding, as well as different strides for
convolutions. And these two will become important pieces
of this convolutional building block of convolutional neural networks, so
let's go on to the next video.