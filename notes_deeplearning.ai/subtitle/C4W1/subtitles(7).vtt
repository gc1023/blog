WEBVTT

1
00:00:00.450 --> 00:00:01.220
In the last video,

2
00:00:01.220 --> 00:00:06.970
you saw the building blocks of a single
convolutional layer of a ConvNet.

3
00:00:06.970 --> 00:00:12.267
Now let's go through a concrete example
of a deep convolutional neural network.

4
00:00:12.267 --> 00:00:14.994
And this will give you some
practice with the notation that we

5
00:00:14.994 --> 00:00:17.300
should use toward the end
of the last video as well.

6
00:00:19.732 --> 00:00:22.288
Let's say you have an image, and

7
00:00:22.288 --> 00:00:27.050
you want to do image classification,
or image recognition.

8
00:00:27.050 --> 00:00:31.523
Where you want to take as input an image
x, and decide, is this a cat or not,

9
00:00:31.523 --> 00:00:32.101
0 or 1.

10
00:00:32.101 --> 00:00:35.866
So it's a neural classification problem,
so

11
00:00:35.866 --> 00:00:41.110
let's build an example of a ConvNet
you could use for this task.

12
00:00:41.110 --> 00:00:47.214
For the sake of this example,
I'm going to use a fairly small image,

13
00:00:47.214 --> 00:00:51.147
let's say this image is 39 by 39 by 3.

14
00:00:51.147 --> 00:00:53.966
This choice just makes some of
the numbers work out a bit better.

15
00:00:53.966 --> 00:00:58.442
And so nh in layer 0 will be equal to nw,

16
00:00:58.442 --> 00:01:02.920
height and width are equal to 39, and

17
00:01:02.920 --> 00:01:08.500
the number of channels in
layer 0 is equal to 3.

18
00:01:08.500 --> 00:01:16.629
Let's say the first layer uses a set
of 3 by 3 filters to detect features.

19
00:01:16.629 --> 00:01:20.065
So f1 is Is equal to three, already f one,

20
00:01:20.065 --> 00:01:25.137
is equal to three because we're
using three by three filters.

21
00:01:25.137 --> 00:01:29.757
And let's say we're using a,
let's try the one and no padding,

22
00:01:29.757 --> 00:01:31.857
so using a same convolution.

23
00:01:31.857 --> 00:01:37.206
And let's say you have 10 filters.

24
00:01:37.206 --> 00:01:42.072
Then, the activations
in this next layer of

25
00:01:42.072 --> 00:01:47.340
the neural network will be 37 by 37 by 10.

26
00:01:47.340 --> 00:01:54.199
And this 10 comes from the fact
that you use 10 filters,

27
00:01:54.199 --> 00:02:01.622
and 37 comes from this formula,
n + 2p- f/s + 1, right?

28
00:02:01.622 --> 00:02:07.570
And I guess you have 39 + 0- 3 / 1 + 1,

29
00:02:07.570 --> 00:02:11.014
that's equal to 37, so

30
00:02:11.014 --> 00:02:16.193
that's why the output is 37 by 37.

31
00:02:16.193 --> 00:02:20.250
It's a valid convolution,
and that's the output size.

32
00:02:20.250 --> 00:02:23.431
So in our notation,

33
00:02:23.431 --> 00:02:29.051
you would have nH1 = nW1 = 37.

34
00:02:29.051 --> 00:02:33.167
And nC1 = 10, so nC1 is equal to

35
00:02:33.167 --> 00:02:39.040
the number of filters
from the first layer.

36
00:02:39.040 --> 00:02:44.710
So this becomes the dimension of
the activation at the first layer.

37
00:02:45.980 --> 00:02:48.650
Let's say you now have another
convolutional layer, and

38
00:02:48.650 --> 00:02:51.580
let's say this time you
use 5 by 5 filters.

39
00:02:51.580 --> 00:02:56.610
So in our notation, f(2) at the next layer
of the neural network is equal to 5.

40
00:02:56.610 --> 00:03:02.310
And let's say use a stride of 2 this time,
and

41
00:03:02.310 --> 00:03:09.720
maybe you have no padding,
and say, 20 filters.

42
00:03:11.758 --> 00:03:18.765
So then the output of this,
Will be another volume,

43
00:03:18.765 --> 00:03:23.553
this time it'll be 17 by 17 by 20.

44
00:03:23.553 --> 00:03:26.354
Notice that because you're
now using a stride of 2,

45
00:03:26.354 --> 00:03:28.416
the dimension has shrunk much faster.

46
00:03:28.416 --> 00:03:35.497
37 by 37 has gone down in size by
slightly more a factor of 2, to 17 by 17.

47
00:03:35.497 --> 00:03:40.140
And because you're using 20 filters,
the number of channels now is 20.

48
00:03:40.140 --> 00:03:44.230
So at its activation,

49
00:03:44.230 --> 00:03:49.613
a2 would be that dimension,

50
00:03:49.613 --> 00:03:54.562
and so nH2 = nW2 = 17,

51
00:03:54.562 --> 00:03:57.808
and nC2 = 20.

52
00:03:57.808 --> 00:04:02.270
All right, let's apply one
last convolutional layer, so

53
00:04:02.270 --> 00:04:07.640
let's say that you use a 5 by 5 filter
again, and again a stride of 2.

54
00:04:07.640 --> 00:04:12.780
So if you do that, I'll skip the math,

55
00:04:12.780 --> 00:04:19.580
you end up with a 7 by 7, and
let's say you use 40 filters.

56
00:04:19.580 --> 00:04:25.210
No padding, 40 filters,
you end up with 7 by 7 by 40.

57
00:04:25.210 --> 00:04:31.087
So now what you've done is
taken your 39 by 39 by 3 image,

58
00:04:31.087 --> 00:04:37.470
and computed your 7 by 7 by
40 features for this image.

59
00:04:37.470 --> 00:04:42.576
And then finally,
what's commonly done is, if you take this

60
00:04:42.576 --> 00:04:47.695
7 by 7 by 40,
7 times 7 times 40 is actually 1960.

61
00:04:47.695 --> 00:04:52.778
And so
we continuously take this volume, and

62
00:04:52.778 --> 00:04:58.414
flatten it, or unroll it, into 1960 units.

63
00:04:58.414 --> 00:05:03.230
Just flatten it out into a vector,
and then feed this

64
00:05:03.230 --> 00:05:08.053
to a logistically rationed unit,
or soft max unit.

65
00:05:10.523 --> 00:05:14.056
Depending on whether you're trying
to recognize cat or no cat, or

66
00:05:14.056 --> 00:05:17.240
trying to recognize any one
of k different objects.

67
00:05:17.240 --> 00:05:23.520
And then just have this give the final
predicted output for the neural network.

68
00:05:23.520 --> 00:05:29.404
And so just be clear, this last step
is just taking all of these numbers,

69
00:05:29.404 --> 00:05:34.910
all 1960 numbers, and
unrolling them into a very long vector.

70
00:05:34.910 --> 00:05:38.005
So then you just have one long
vector to feed into soft max,

71
00:05:38.005 --> 00:05:42.440
until it's just a regression, in order to
make a prediction for the final output.

72
00:05:44.270 --> 00:05:48.410
So this would be a pretty
typical example of a ConvNet.

73
00:05:50.050 --> 00:05:53.120
A lot of the work in designing
a convolutional neural

74
00:05:53.120 --> 00:05:55.924
net is selecting
hyperparameters like these.

75
00:05:55.924 --> 00:06:00.715
Deciding what's the filter size,
what's the stride, what's the padding,

76
00:06:00.715 --> 00:06:02.512
and how many filters you use.

77
00:06:02.512 --> 00:06:06.653
And both later this week as well as next
week, we'll give some suggestions and

78
00:06:06.653 --> 00:06:09.110
some guidelines on how
to make these choices.

79
00:06:10.110 --> 00:06:15.570
But for now, maybe one thing to take
away from this is that, as you go deeper

80
00:06:15.570 --> 00:06:20.920
in the neural network, typically you
start out with larger images, 39 by 39.

81
00:06:20.920 --> 00:06:25.020
And then the height and
width will stay the same for awhile,

82
00:06:25.020 --> 00:06:28.790
and gradually trend down as you
go deeper in your networks.

83
00:06:28.790 --> 00:06:33.274
It's gone from 39 to 37 to 17 to 40,
excuse me, so

84
00:06:33.274 --> 00:06:36.487
it's gone from 39 to 37 to 17 to 7.

85
00:06:36.487 --> 00:06:41.132
Whereas the number of channels
will generally increase,

86
00:06:41.132 --> 00:06:44.457
it's gone from 3 to 10 to 20 to 40.

87
00:06:44.457 --> 00:06:47.692
And you see this general trend in
a lot of other convolutional neural

88
00:06:47.692 --> 00:06:48.610
networks as well.

89
00:06:49.790 --> 00:06:53.260
And we'll give more guidelines about
how to design these parameters in

90
00:06:53.260 --> 00:06:54.190
later videos.

91
00:06:55.320 --> 00:06:59.690
But you've now seen your first example
of a convolutional neural network,

92
00:06:59.690 --> 00:07:01.870
or ConvNet for short.

93
00:07:01.870 --> 00:07:05.000
So congratulations on that, and

94
00:07:05.000 --> 00:07:10.530
it turns out that in a typical ConvNet,
there are usually three types of layers.

95
00:07:10.530 --> 00:07:16.330
One is the convolutional layer, and often
we'll often donate that as a conv layer,

96
00:07:16.330 --> 00:07:19.700
that's what we've been using
in the previous network.

97
00:07:19.700 --> 00:07:23.811
It turns out that there's two other common
types of layers that you haven't seen yet,

98
00:07:23.811 --> 00:07:26.610
but we'll talk about in
the next couple videos.

99
00:07:26.610 --> 00:07:31.297
One is called a pooling layer,
often I'll call this pool, and

100
00:07:31.297 --> 00:07:34.934
the last is a fully connected layer,
called FC.

101
00:07:34.934 --> 00:07:37.743
And although it's possible
to design a pretty good

102
00:07:37.743 --> 00:07:40.565
neural network using just
convolutional layers.

103
00:07:40.565 --> 00:07:44.629
Most neural networks architectures will
also have a few pooling layers, and

104
00:07:44.629 --> 00:07:46.265
a few fully connected layers.

105
00:07:49.002 --> 00:07:50.813
Fortunately, pooling layers and

106
00:07:50.813 --> 00:07:55.005
fully connected layers are a bit simpler
than convolutional layers to define.

107
00:07:56.820 --> 00:08:01.420
So we'll do that quickly in the next two
videos, and then you have a sense of

108
00:08:01.420 --> 00:08:05.960
all of the most common types of layers
in a convolutional neural network.

109
00:08:05.960 --> 00:08:09.861
And you'll be able to put together
even more powerful networks

110
00:08:09.861 --> 00:08:11.416
than the one we just saw.

111
00:08:11.416 --> 00:08:16.780
So congrats again on seeing your first
full convolutional neural network.

112
00:08:16.780 --> 00:08:20.970
We'll also talk later in this week
about how to train these networks.

113
00:08:20.970 --> 00:08:24.850
But first, let's talk briefly about
pooling and fully connected layers.

114
00:08:24.850 --> 00:08:25.891
And then training these,

115
00:08:25.891 --> 00:08:28.880
we'll be using back propagation,
which you're already familiar with.

116
00:08:28.880 --> 00:08:30.158
But in the next video,

117
00:08:30.158 --> 00:08:34.549
I'll just quickly go over how to implement
a pooling layer for your ConvNet.