WEBVTT

1
00:00:00.000 --> 00:00:03.150
Welcome to this course on convolutional networks.

2
00:00:03.150 --> 00:00:05.430
Computer vision is one of the areas that's been

3
00:00:05.430 --> 00:00:08.055
advancing rapidly, thanks to deep learning.

4
00:00:08.055 --> 00:00:11.490
Deep learning computer vision is now helping self-driving cars,

5
00:00:11.490 --> 00:00:15.320
figure out where are the other cars and the pedestrians around us so as to avoid them.

6
00:00:15.320 --> 00:00:18.825
Is making face recognition work much better than ever before,

7
00:00:18.825 --> 00:00:21.660
so that perhaps some of you will soon or perhaps already,

8
00:00:21.660 --> 00:00:23.250
be able to unlock a phone,

9
00:00:23.250 --> 00:00:25.925
unlock even a door using just your face.

10
00:00:25.925 --> 00:00:27.435
And if you look on your cell phone,

11
00:00:27.435 --> 00:00:29.680
I bet you have many apps that show you pictures of food or

12
00:00:29.680 --> 00:00:32.790
pictures of a hotel or just fun pictures of scenery.

13
00:00:32.790 --> 00:00:34.980
And some of the companies that build those apps are

14
00:00:34.980 --> 00:00:37.875
using deep learning to help show you the most attractive,

15
00:00:37.875 --> 00:00:40.475
the most beautiful, or the most relevant pictures.

16
00:00:40.475 --> 00:00:45.410
And I think deep learning is even enabling new types of art to be created.

17
00:00:45.410 --> 00:00:48.075
So, I think the two reasons I'm excited

18
00:00:48.075 --> 00:00:51.690
about deep learning for computer vision and why I think you might be too.

19
00:00:51.690 --> 00:00:57.271
First, rapid advances in computer vision are enabling brand new applications to be able.

20
00:00:57.271 --> 00:00:59.990
They just weren't possible a few years ago.

21
00:00:59.990 --> 00:01:01.230
And by learning these tools,

22
00:01:01.230 --> 00:01:06.030
perhaps you will be able to invent some of these new products and applications.

23
00:01:06.030 --> 00:01:09.775
Second, even if you don't end up building computer vision systems per se,

24
00:01:09.775 --> 00:01:13.740
I found that because the computer vision research community has been so

25
00:01:13.740 --> 00:01:15.930
creative and so inventive in coming up

26
00:01:15.930 --> 00:01:18.134
with new neural network architectures and algorithms,

27
00:01:18.134 --> 00:01:23.010
is actually inspire that creates a lot of cross-fertilization into other areas as well.

28
00:01:23.010 --> 00:01:25.290
For example, when I was working on speech recognition,

29
00:01:25.290 --> 00:01:27.840
I sometimes actually took inspiration from ideas

30
00:01:27.840 --> 00:01:31.270
from computer vision and borrowed them into the speech literature.

31
00:01:31.270 --> 00:01:33.570
So even if you don't end up working in computer vision,

32
00:01:33.570 --> 00:01:36.892
I hope that you find some of the ideas you learn about in this course helpful

33
00:01:36.892 --> 00:01:41.244
for some of your algorithms and your architectures.

34
00:01:41.244 --> 00:01:43.290
So with that, let's get started.

35
00:01:43.290 --> 00:01:48.570
Here are some examples of computer vision problems we'll study in this course.

36
00:01:48.570 --> 00:01:50.806
You've already seen image classification,

37
00:01:50.806 --> 00:01:52.650
sometimes also called image recognition,

38
00:01:52.650 --> 00:01:58.615
where you might take as input say a 64 by 64 image and try to figure out is that a cat.

39
00:01:58.615 --> 00:02:02.870
Another example of the computer vision problem is object detection.

40
00:02:02.870 --> 00:02:04.695
So if you're building a self-driving car,

41
00:02:04.695 --> 00:02:08.530
maybe you don't just need to figure out that there are other cars in this image.

42
00:02:08.530 --> 00:02:11.760
But instead, you need to figure out the position of the other cars

43
00:02:11.760 --> 00:02:15.100
in this picture so that your car can avoid them.

44
00:02:15.100 --> 00:02:17.250
So in object detection usually we have to not

45
00:02:17.250 --> 00:02:19.560
just figure out there are these other objects,

46
00:02:19.560 --> 00:02:20.835
say, cars and picture,

47
00:02:20.835 --> 00:02:23.760
but also draw boxes around them.

48
00:02:23.760 --> 00:02:29.100
Or have some other way of recognizing where in the picture are these objects.

49
00:02:29.100 --> 00:02:30.990
And notice also, in this example,

50
00:02:30.990 --> 00:02:34.121
that they can be multiple cars in the same picture

51
00:02:34.121 --> 00:02:38.515
or at least every one of them within a certain distance of your car.

52
00:02:38.515 --> 00:02:42.560
Here's another example, maybe a more fun one is neural style transfer.

53
00:02:42.560 --> 00:02:49.305
Let's say you have a picture and you want this picture repainted in a different style.

54
00:02:49.305 --> 00:02:50.740
So neural style transfer,

55
00:02:50.740 --> 00:02:54.245
you have a content image and you have a style image.

56
00:02:54.245 --> 00:02:56.370
The image on the right is actually a Picasso.

57
00:02:56.370 --> 00:03:01.590
And you can have a neural network put them together to repaint the content image,

58
00:03:01.590 --> 00:03:04.335
that's this image on the left, but in the style of

59
00:03:04.335 --> 00:03:08.730
the image on the right and you end up with the image at the bottom.

60
00:03:08.730 --> 00:03:12.395
So algorithms like these are enabling new types of artwork to be created.

61
00:03:12.395 --> 00:03:15.980
And in this course, you'll learn how to do this yourself as well.

62
00:03:15.980 --> 00:03:21.185
One of the challenges of computer vision problems is that the inputs can get really big.

63
00:03:21.185 --> 00:03:23.040
For example, in previous courses,

64
00:03:23.040 --> 00:03:25.230
you've worked with 64 by 64 images.

65
00:03:25.230 --> 00:03:29.030
And so that 64 by 64 by 3 because there're color channels.

66
00:03:29.030 --> 00:03:30.705
And if you multiply that out,

67
00:03:30.705 --> 00:03:32.490
that's 1, 2, 2, 8, 8.

68
00:03:32.490 --> 00:03:35.760
So X, the input features has dimension 1,

69
00:03:35.760 --> 00:03:37.115
2, 2, 8, 8.

70
00:03:37.115 --> 00:03:38.640
And that's not too bad,

71
00:03:38.640 --> 00:03:42.105
but 64 by 64 is actually a very small image.

72
00:03:42.105 --> 00:03:44.085
If you work with larger images,

73
00:03:44.085 --> 00:03:51.095
maybe this is a 1,000 pixel by 1,000 pixel image and that's actually just one megapixel.

74
00:03:51.095 --> 00:03:56.190
But the dimension of the input features will be 1,000 by 1,000 by

75
00:03:56.190 --> 00:04:02.382
3 because you have three RGB channels and that's three million.

76
00:04:02.382 --> 00:04:04.632
And if you are viewing this on a smaller screen,

77
00:04:04.632 --> 00:04:08.440
this might not be apparent that this is actually a low risk 64 by 64 image,

78
00:04:08.440 --> 00:04:11.400
and this is a higher risk 1,000 by 1,000 image.

79
00:04:11.400 --> 00:04:14.190
But if you have three million input features,

80
00:04:14.190 --> 00:04:21.155
then this means that X here will be three million dimensional.

81
00:04:21.155 --> 00:04:23.860
And so if in the first hidden layer,

82
00:04:23.860 --> 00:04:27.525
maybe you have just 1,000 hidden units,

83
00:04:27.525 --> 00:04:31.145
then the total number of weights,

84
00:04:31.145 --> 00:04:36.240
that is the matrix W1.

85
00:04:36.240 --> 00:04:39.330
If you use a standard fully connected network,

86
00:04:39.330 --> 00:04:42.620
like we have in courses one or two,

87
00:04:42.620 --> 00:04:47.400
this matrix will be a 1,000 by

88
00:04:47.400 --> 00:04:55.425
three million dimensional matrix because X is now R by three million.

89
00:04:55.425 --> 00:04:57.765
3m am using to denote three million.

90
00:04:57.765 --> 00:05:02.200
And this means that this matrix here will have three billion parameters,

91
00:05:02.200 --> 00:05:05.140
which is just very, very large.

92
00:05:05.140 --> 00:05:06.820
And with that many parameters,

93
00:05:06.820 --> 00:05:10.210
it's difficult to get enough data to prevent

94
00:05:10.210 --> 00:05:14.285
a neural network from overfitting and also the competition requirements.

95
00:05:14.285 --> 00:05:18.450
The memory requirements to train in neural network with three billion parameters,

96
00:05:18.450 --> 00:05:21.215
it's just a bit infeasible.

97
00:05:21.215 --> 00:05:22.688
But for computer vision applications,

98
00:05:22.688 --> 00:05:25.660
you don't want to be stuck using only tiny little images,

99
00:05:25.660 --> 00:05:27.880
you want to be able to use large images.

100
00:05:27.880 --> 00:05:30.070
To do that, you need to be the implement

101
00:05:30.070 --> 00:05:32.650
the convolution operation which is one of

102
00:05:32.650 --> 00:05:35.955
the fundamental building blocks of convolutional neural networks.

103
00:05:35.955 --> 00:05:39.340
Let's see what this means and how you can implement this in the next video.

104
00:05:39.340 --> 00:05:43.410
I will illustrate convolutions using the example of age detect.