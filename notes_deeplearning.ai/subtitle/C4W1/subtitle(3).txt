In order to build deep neural networks, one modification to the basic convolutional operation that you need to really use is padding. Let's see how it works. What we saw in earlier videos is that if you take a six-by-six image and convolve it with a three-by-three filter, you end up with a four-by-four output with a four-by-four matrix. And that's because, the number of possible positions for your three-by-three filter, there are only sort of four-by-four possible positions for the three-by-three filter to fit in your six-by-six matrix. The math for this turns out to be that if we have a n-by-n image, and to involve that with an f-by-f filter, then the dimension of the output will be n minus f plus one by n minus f plus one. In this example, six minus three plus one is equal to four, which is why you wind up with four-by-four output. The two downsides to this, one is that every time you apply a convolutional operator, your image shrinks so you come from six-by-six down to four-by-four, then you can only do this a few times before your image starts getting really small. Maybe it strings down to one-by-one or something, so maybe you don't want your image to shrink every time you touch the edges or install other features on it, so that's one downside. And the second downside is that, if you look the pixel at the corner or the edge, this little pixel is touched, it has used only in one of the outputs, because this touches that three-by-three region. Whereas, if you take a pixel in the middle, say this pixel, then there are a lot of the three-by-three regions that overlap that pixel, and so it's as if pixels on the corners or on the edges are used much less in the output, so you're throwing away a lot of the information near the edge of the image. So to solve both of these problems, both the shrinking output, and when we build really deep neural networks, you'll see why you don't want the image to shrink on every step because if you have maybe 100 layer deep net, then the strings that are on every layer then after 100 layers, you end up with a very small image. So that was one problem. The other is throwing away a lot of the information from the edges of the image. So in order to fix both of these problems, what you can do is, the full upon the convolutional operation, you can pad the image. So in this case, let's say you pad the image with an additional border of one pixel all around the edges. So if you do that, then the six-by-six image, you've now padded this to eight-by-eight image. And if you convolve an eight-by-eight image with a three-by-three image, you now get that out, now the four-by-four by the six-by-six images. So you managed to preserve the original input size of six-by-six. So by convention, when you padded with zeros, and p is the padding amounts. So in this case, p is equal to one, because we're padding all around with an extra border of one pixels, that the output becomes n plus two p minus f plus one, by n plus two p minus f by one. So this become six plus two times one, minus three plus one, by the same thing on that. So six plus two minus three plus one, that's equals to six. So you end up with a six-by-six image. That's the image appearance at that point. So this green pixel actually influences all of these cells of the output, and so this effective, maybe not quite throwing away but counting less the information from the edge of a corner or the edge of the image is reduced. And I've shown here the effects of having the border with just one pixel. If you want, you can also pad the border with two pixels. In which case, I guess you add on another border here, and take and pad it with even more pixels if you choose. So I guess what I'm trying here, this would be a pad of p equals two. In terms of how much to pad, this time there are two common choices. They are called Valid convolutions and Same convolutions. Not really great things, but in a valid convolution, this basically means no padding. And so in this case, you might have an n-by-n image, convolve with an f-by-f filter, and this would give you an n minus f plus one by n minus f plus one dimensional output. So this is like the example we had previously from the previous videos where we had an n-by-n image convolve with a three-by-three filter, and that gave you a four-by-four output. The other most common choice or padding is called the Same Convolution. And that means when you pad, so the output size is the same as the input size. So, if you actually look at this formula, when you pad by p pixels, then it's as if n goes to n plus two p, and then you have from the rest of this, minus f plus one. So even n-by-n image, and the padding of a border of p pixels all around, then the output size is a big destination, n plus two p minus f plus one. And so if you want n plus two p minus f plus 1 to be equal to 1, so that the output size is same as the input size, if you take this and solve for, I guess it cancels out on both sides, and if you solve for p, this implies that p is equal to f minus one over two. So when f is odd, by choosing the padding size to be as follows, you should make sure that the output size is same as the input size. And that's why, for example, when the filter was three-by-three as the example on the previous slide, the padding that would make the upper size the same as the input size was three minus one over two, which is one. And as another example, if your filter was five-by-five, so f is equal to five, then if you plug it into that equation, you find that the padding of two is required to keep the output size the same as the input size when the filter is five-by-five. By convention, in computer vision, f is usually odd. It's actually almost always odd. And you rarely see an even-numbered filters, filter words using computer vision. And I think there are two reasons for that. One is that if f was even, then you need some asymmetric padding, or it's only f is not that this type of same convolution gives a natural padding. We can pad the same dimension all around them, pad more on the left and pad less on the right or something asymmetric. And then second, when you have an automation filter, such as three-by-three or five-by-five, then it has a central position and sometimes in computer vision, it's nice to have a distinguisher. It's nice to have a pixel you can call the central pixel, so you can talk about the position of the filter. Maybe none of this is a great reason for using f to be pretty much always odd, but if you look at convolution literature, you see three-by-three filters are very common, you see some five-by-five, seven-by-seven. And that is sometimes later, we will also talk about one-by-one filters and one that makes sense. But just by convention, I recommend you just use odd-numbered filters as well. I think that you can probably get just fine performance even if you want to use an even number value for f, but if you stick to the common computer vision convention, I usually just use odd-numbered f. So you've now seen how to use padding convolutions. To specify the padding for the convolution operation, you can either specify the value for p, or you can just say that this is a valid convolution which means p equals zero, or you can say this is the same convolution which means pad as much as you need to make sure the output has same dimension as the input. So that's it for padding. In the next video, let's talk about how you can implement Strided Convolution.