{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C4W1 - 卷积神经网络\n",
    "---\n",
    "内容概要\n",
    "\n",
    "1. convolutions and Why convolutions?\n",
    "2. 边缘检测（edge detection）\n",
    "3. Padding\n",
    "4. Strided convolutions\n",
    "5. Convolutions over volumes\n",
    "6. A simple convolution network example\n",
    "7. Pooling layers（Max pooling、Average pooling）\n",
    "8. Convolutional neural network example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - 为什么需要卷积神经网络？\n",
    "\n",
    "---\n",
    "\n",
    "在Course1中，ng已经向我们展示了用标准神经网络（又称全连接神经网络）来处理图像分类任务，即识别图片中是否有猫。那么，为什么还需要卷积神经网络呢？\n",
    "\n",
    "需要注意的是，Course1中处理的图片大小为 $64\\times64\\times3$，使用全连接神经网络，其第一个隐含层的权重参数只有12288个；如果图片大小为 $1000\\times1000\\times3$，那么权重参数将会是1百万个。也就是说，随着图片的增大，全连接神经网络的参数数量会急剧增多，这造成两个问题：1）神经网络的训练时长大幅上升；2）容易过拟合。\n",
    "\n",
    "由此可见，当处理图像变大之后，使用全连接神经网络对其进行处理是行不通的，最主要的原因就是参数太多了。在卷积神经网络中，有两种方法可以大幅降低参数数量，分别是：1、权值共享（parameter sharing）；2、稀疏连接（sparsity of connections），又称局部感知。\n",
    "\n",
    "Parameter sharing 中隐含的假设是图像中任一部分的统计特性与其他部分是一样的，这意味着，对图像中某一部分有效的特征检测器（feature detector）在图像的其他部分同样有效。\n",
    "\n",
    "Sparsity of connections 的意思是，在网络中的每一层的每一个输出值仅依赖于图像输入的很小一部分区域。\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - 卷积（convolutions）\n",
    "\n",
    "---\n",
    "\n",
    "典型的卷积过程如下图所示：\n",
    "<img src=\"images/Conv2D.gif\" style=\"width:200px\">\n",
    "\n",
    "上图中，黄色的$3\\times3$矩阵为filter（过滤器，也有人称之为卷积核）。所谓卷积，就是filter在image矩阵上按照一定的规律移动、计算点积的过程。\n",
    "\n",
    "关于点积，请查看：https://en.wikipedia.org/wiki/Dot_product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 -  边缘检测（edge detection）\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 - padding\n",
    "\n",
    "---\n",
    "\n",
    "使用 $f\\times f$ 的filter在大小为 $n\\times n$ 的矩阵上进行卷积操作，得到的结果矩阵会比原始矩阵小。但是，有的时候，我们并不希望结果矩阵比原始矩阵更小。此时，我们就需要对原始矩阵进行padding（填充）操作。\n",
    "\n",
    "padding操作，其实就是在原始矩阵的四周填上合适数量的数值（通常是0），使得 $f\\times f$ 的filter在矩阵上进行卷积操作之后能够得到与原始矩阵大小一样的结果矩阵。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 - strided convolutions\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 2.4 - Convolutions over volumes\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  2.5 - Multiple filters\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Pooling\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 立体卷积\n",
    "---\n",
    "\n",
    "filter和图像的channels要一致。\n",
    "\n",
    "## 单层CNN\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "核 = 过滤器\n",
    "\n",
    "\n",
    "垂直边缘检测器\n",
    "\n",
    "卷积运算理解与实现\n",
    "实现卷积运算：\n",
    "python: conv-forward\n",
    "tensorflow: tf.nn.conv2d\n",
    "keras: Conv2D\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "卷积操作的两个问题：\n",
    "1. 卷积之后，图像变小\n",
    "2. 边缘仅被卷积一次，信息丢失\n",
    "\n",
    "padding convolutions\n",
    "用像素填充边缘\n",
    "p = (f-1)/2\n",
    "\n",
    "Valid and Same convolutions\n",
    "\n",
    "filter的大小f为什么通常是奇数？\n",
    "1. 方便padding操作\n",
    "2. f是奇数的filter有一个中心点，便于计算操作，指出filter位置\n",
    "\n",
    "---\n",
    "strided convolution -- 卷积步长\n",
    "\n",
    "---\n",
    "cross-correlation vs convolution\n",
    "\n",
    "convolution计算之前，需要将filter做一个镜像（水平和竖直方向），然后进行点乘求和\n",
    "cross-correlation计算，直接使用filter进行点乘求和；\n",
    "通常，在CNN中，使用convolution操作更多、更有效\n",
    "\n",
    "--\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 群内讨论总结\n",
    "\n",
    "---\n",
    "\n",
    "JamesDai:\n",
    "原始的CNN的分类能力强过检测能力?\n",
    "我:\n",
    "没有听过这类说法，检测和分类的界限，感觉很模糊吧\n",
    "我:\n",
    "比如，要想把有猫的图片分开，肯定要先检测图片中有没有猫\n",
    "JamesDai:\n",
    "分类=“图片里有什么”或”属于什么”\n",
    "JamesDai:\n",
    "检测=“标定出特定的目标”\n",
    "我:\n",
    "这么定义的话，检测就是比分类更高一层的任务了。原始的CNN设计之初感觉就是为了分类\n",
    "JamesDai:\n",
    "我觉得也是. \n",
    "我:\n",
    "检测的话就是imagenet竞赛开始之后，出现的很多CNN变种网络\n",
    "\n",
    "---\n",
    "\n",
    "JamesDai:\n",
    "卷积的运算特性导致了对”平移不变性”有了良好的特性\n",
    "JamesDai:\n",
    "但是对于”旋转不变性”的特性就非常弱了,或者是勉强能应付一下小角度的旋转.\n",
    "\n",
    "旋转不变性的解决，可以通过样本数据集的扩样实现，即：将图片旋转生成新的样本。\n",
    "\n",
    "卷积的运算特性导致了对”平移不变性”有了良好的特性  这里的运算特性指的是从左到右 从上到下吗？\n",
    "不旋转之外的移动,沿着斜线移动也可\n",
    "\n",
    "平移不变性指的是 无论这个feature 在图像中哪个位置，都可以被检测出吗？\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [梯度上升可视化卷积神经网络](https://mp.weixin.qq.com/s/tpfmh4PTMjFaMHKZLZw3Pg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
